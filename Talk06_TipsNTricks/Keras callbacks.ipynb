{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Callbacks\n",
    "\n",
    "This is to show implementations of Keras Callbacks and how to use them\n",
    "\n",
    "- 1 Basic History and plotting  \n",
    "- 2 TensorBoard implementation  \n",
    "- 3 Model checkpoints  \n",
    "- 4 Early Stopping  \n",
    "- 5 Learning Rate Scheduler  \n",
    "- 6 ReduceLROnPlateau  \n",
    "- 7 LambdaCallback "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11321344/11490434 [============================>.] - ETA: 0s60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense1 (Dense)               (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,),name='Dense1'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu',name='Dense2'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic History and ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5s - loss: 0.2454 - acc: 0.9251 - val_loss: 0.1043 - val_acc: 0.9686\n",
      "Epoch 2/10\n",
      "4s - loss: 0.1014 - acc: 0.9685 - val_loss: 0.0855 - val_acc: 0.9752\n",
      "Epoch 3/10\n",
      "4s - loss: 0.0755 - acc: 0.9778 - val_loss: 0.0772 - val_acc: 0.9785\n",
      "Epoch 4/10\n",
      "4s - loss: 0.0623 - acc: 0.9815 - val_loss: 0.0799 - val_acc: 0.9797\n",
      "Epoch 5/10\n",
      "4s - loss: 0.0517 - acc: 0.9847 - val_loss: 0.0804 - val_acc: 0.9803\n",
      "Epoch 6/10\n",
      "4s - loss: 0.0452 - acc: 0.9870 - val_loss: 0.0885 - val_acc: 0.9791\n",
      "Epoch 7/10\n",
      "4s - loss: 0.0397 - acc: 0.9882 - val_loss: 0.0734 - val_acc: 0.9829\n",
      "Epoch 8/10\n",
      "4s - loss: 0.0353 - acc: 0.9902 - val_loss: 0.0905 - val_acc: 0.9793\n",
      "Epoch 9/10\n",
      "5s - loss: 0.0323 - acc: 0.9907 - val_loss: 0.0851 - val_acc: 0.9824\n",
      "Epoch 10/10\n",
      "4s - loss: 0.0316 - acc: 0.9910 - val_loss: 0.1063 - val_acc: 0.9791\n",
      "Test loss: 0.106284460687\n",
      "Test accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XXW59/3PlTnN3CRN2qRtOiYtbWkhFkoBgQoUEBnE\nA85wwAqCoI96DnrOUfTRW7z1+AD3QTmI9cYjgogWUcsoYWpa6DxP2emUtE2TtJnn7Ov5Y62kuyFt\nd5usrAzX+/XKK3uvYa9r7zbru3/rt9ZviapijDHGnE6E3wUYY4wZGiwwjDHGhMUCwxhjTFgsMIwx\nxoTFAsMYY0xYLDCMMcaExQLDmH4iIv9XRH4Y5rJ7ReRjXtdkTH+ywDDGGBMWCwxjjDFhscAwI4p7\nKOhbIrJJRBpF5NcikiUiL4tIvYi8ISJpIct/QkS2ikiNiLwlIjNC5s0TkXXuen8A4nps6+MissFd\nt1hE5oRZ43Uisl5E6kTkgIg81GP+xe7r1bjzb3enx4vIf4rIPhGpFZH3RCS+Dx+XMSewwDAj0SeB\nK4HpwPXAy8B3gEycv4n7AURkOvAs8DV33nLgryISIyIxwIvA/wCjgT+6r4u77jxgKfBlIB34b+Al\nEYkNo75G4AtAKnAdcI+I3Oi+7kS33v/j1jQX2OCu9zPgfOAit6Z/AYJn9MkYcwoWGGYk+j+qWqGq\n5cC7wPuqul5VW4BlwDx3uVuBv6vq66rajrNDjsfZIV8IRAOPqGq7qr4ArA7ZxhLgv1X1fVXtVNWn\ngVZ3vVNS1bdUdbOqBlV1E05ofdSd/RngDVV91t1utapuEJEI4J+BB1S13N1msaq29umTMiaEBYYZ\niSpCHjf38jzRfTwO2Nc1Q1WDwAEgx51XrieO3rkv5PFE4BvuYaMaEakBxrvrnZKIXCAiRSJSKSK1\nwN1Ahjt7PBDoZbUMnENivc0zpl9YYBhzcgdxdvwAiIjg7LDLgUNAjjuty4SQxweAH6lqasjPKFV9\nNozt/h54CRivqinAE0DXdg4AU3pZpwpoOck8Y/qFBYYxJ/c8cJ2ILBKRaOAbOIeVioGVQAdwv4hE\ni8jNwPyQdX8F3O22FkREEtzO7KQwtpsEHFXVFhGZj3MYqsszwMdE5J9EJEpE0kVkrtv6WQr8XETG\niUikiCwIs8/EmLBYYBhzEqq6E/gcTgdzFU4H+fWq2qaqbcDNwO3AUZz+jj+HrLsG+BLwX8AxoMRd\nNhxfAX4gIvXAd3GCq+t19wPX4oTXUZwO73Pd2d8ENuP0pRwFfoL9jZt+JHYDJWOMMeGwbx/GGGPC\nYoFhjDEmLBYYxhhjwmKBYYwxJixRfhfQnzIyMjQvL8/vMowxZshYu3ZtlapmhrPssAqMvLw81qxZ\n43cZxhgzZIjIvtMv5bBDUsYYY8JigWGMMSYsFhjGGGPCYoFhjDEmLBYYxhhjwmKBYYwxJiwWGMYY\nY8IyrK7DMMaYwUZV6QgqHZ1KW2eQjs4gHUGlrSPoTg+605WOYJC2Duf38eW7ph9fvr1TaXdfp70z\nSGxUJPdc5v29szwNDBFZDDwKRAJPqerDPean4dz0ZQrO3cL+WVW3uPMewLmfgAC/UtVHvKzVGDPy\ndHQGaWzrpLG1g8bWDhpaO2hs7aSxrSNkWmfIvA4a25xpTa0dNLV1du+4nR36h3f07Z3e30JiTFLs\n0A4MEYkEHgeuBMqA1SLykqpuC1nsO8AGVb1JRArc5ReJyCycsJgPtAGviMjfVLXEq3qNMUODqlLZ\n0Epdc8eJO/o2d2ffc0ffY+ff1HZ8nZb2YFjbjBBIiI0iISaKhNhIEmOjSIiNInVUNNGREURHRhAV\nKURHuL8jI4iOFKLcedERXY/l+LJdy0RE9FjeXSZCTnjtGPd3VETE8cfuNiMi5PRvoh942cKYD5So\naimAiDwH3ACEBsZM4GEAVd0hInkikgXMAN5X1SZ33bdx7m72vz2s1xgzyNQ0tbHzcD07K+rZcbie\nXe7j+paOU64nQvfOPSE2ytnBx0SRkxpDYmwko0KmhQZAYmwUo2JC1nF/x0VHcOLt20cmLwMjB+eG\n9V3KgAt6LLMRJwjede9dPBHIBbYAPxKRdKAZ55aUvQ4SJSJLgCUAEyZM6M/6jTEDpKW9k5IjDU4o\nuOGw83AdFXWt3cskx0VRkJ3MjXNzmJaVSOqoGBJ67Ny7dv7x0ZG2g/eA353eDwOPisgGnHsRrwc6\nVXW7iPwEeA1oxLlvcWdvL6CqTwJPAhQWFtr9Zo0ZxDqDyr7qxpBQcH72VjcSdP96Y6IimDYmkYVT\nM8jPSiI/O4mC7GSykmMtBHzmZWCUA+NDnue607qpah1wB4A4/xP2AKXuvF8Dv3bn/S+cFooxZghQ\nVSrrW7tDoavlsPtIfXe/gQjkpScwPSuRj587joJsJxwmjh5FVKSd8T8YeRkYq4FpIjIJJyhuAz4T\nuoCIpAJNqtoG3AW844YIIjJGVY+IyAScw1YXelirMeYs1be0d7cYdrnhsLOinpqm9u5lMpNiKchO\n4nMXTCTfDYZpY5KIj4n0sXJzpjwLDFXtEJH7gFdxTqtdqqpbReRud/4TOJ3bT4uIAluBO0Ne4k9u\nH0Y7cK+q1nhVqzHm1FSVY03tHKpt7u5r6DqcVF7T3L1cYmwU07MSuWbWWPKzEsnPTiY/O4nRCTE+\nVm/6i6gOn8P+hYWFajdQMubMtHcGOVLfyuHaZg7XtnK4rsV5XNdKRW2L87yuhbaO46egRkcKUzIT\nmd7dx+D8zkmNt36GIUZE1qpqYTjL+t3pbYzxUH1LOxV1LT2CoOu5ExDVja30/N4YGxVBdkoc2clx\nzJuQSnZyXPfzyZmJTMpIICbK+hlGGgsMY4agYFCpamyloraVQ7XNTiicEAQtVNS10tD64esV0kZF\nk+UGwOycFOdxchxZKXGMdUMhJT7aWgrmQywwjBmkVJX9R5vYXF7L5vJaDhxt6g6CiroWOoInNgui\nIoQxSbFkp8SRn53EpdMzT2gZZKfEkZUcR1y0dTSbs2OBYcwgoKqUHWtmU1mtGxA1bCmvo7bZOdMo\nJjKC8aPjyU6J44LJo7tbAl0theyUODISYgdsiAgzMllgGDPAusJhS3ktm8pr2eK2ILpOQ42OFAqy\nk7l29ljm5KYwOyeF6VlJ1mdgfGeBYYyHVJWDtS1sLnNaDZvL69hcVsMxNxyiIoT87CQWn5PN7NwU\n5uSkMj07kdgoO2xkBh8LDGP6iapyuK6FTWVOq6Hrd3VjGwCREcL0rCSumpnNrNwU5uSkkJ+dZH0K\nZsiwwDDmLFW44bC5rKa7Y7qq4Xg4TBuTyBUFY5iTm8KsnBRmjE22cDBDmgWGMWE4UtfC5pBWw6by\nWirrnZFUIwSmjUnisvwxzM5JYXZuCjMtHMwwZIFhTC8q61t5e1clRTuPsGbv0e5htiMEpo5J5JJp\nGcxxw2HG2GRGxdifkhn+7H+5MTjDbm8sq+GtHUco2lnJ5vJawLn15UVT0pmTm9rdckiItT8bMzLZ\n/3wzYh1rbOOd3ZUU7TjC27sqOdbUToTAeRPS+NbV+VyWn8nMscl2xbMxLgsMM2IEg8rWg3UU7TxC\n0c4jbDhQgyqMTojh8vwxXFYwhkunZZA6ykZWNaY3FhhmWKttbue93VUU7TzCWzsrqWpoRQTm5Kby\nwKJpXJY/hjk5KXaFtDFhsMAww4qqsuNwfXdArN13jM6gkhIfzaXTM7k8P5NLp2eSkRjrd6lDT2cH\nHNoAaXmQkOF3NcYHFhhmyGto7WBFSRVv7TxC0Y5KDte1AHDOuGTu+egULi/I5NzcVLvt59kIdsK+\nYti6DLa/BI2VIBEw4SKYcT3M+Dik5PpdpRkgFhhmyFFVApUNFO2o5K1dR/hgz1HaO5XE2CgumZbB\n5flj+Gh+JlnJcX6XOjQFg3BglRMS2/4CDRUQPQqmXw3510H1btj+V3jlX52fcec5wTHjE5Axze/q\nvddSB3vfhZJ/wNFSyFsI066G7NnOjcqHMbvjnhkSmts6WVlaRdEO59qIsmPObUHzs5K4LD+Ty/LH\nUJiXRrS1Is5OMAhlq92QeBHqD0FUHEy7Cs65yQmLmIQT16kqgR1/dcKjfK0zLbPAbXlcD9lzhscO\nNNjpHIoreRMCb0LZBxDsgOgESJ0Aldud5ZLGwbQrnc9q8mUf/rwGqTO5454Fhhm09lY1OoeZdlay\nsrSato4g8dGRLJyaweUFTkjkpMb7XebQpers6Lcug60vQl0ZRMY6O71zboLpiyE2MbzXqi2DHX93\nwmPfCtCgszMtcMNj/HyIGEJXvteWO+EQeBNKi6D5mDN97LkwZRFMuQLGXwBRMVB/GHa/DrtfhcBb\n0FYPkTGQd7HzGU67CkZP8vXtnIoFhhmSVJXdRxr4+6ZDvLzlELsqGgCYnJngnPaan8n8SaNtJNe+\nUHW+LW/5sxMStfshIhqmfswJifxrIC65b9torIKdLzvhUVoEnW2QMAYKrnPCI+8SZ0c7mLQ1OX01\ngTch8A+o3OFMT8x2wmHqIqfVcLrO/o422F8Mu15zAqS6xJmeMd0JjulXw4QFEBnt5bs5IxYYZsjo\nOqvp5c2H+PvmQwQqGxGB+XmjWTwrmysKxjAxfWg07QctVTi8Gbb+2WlNHNsLEVHOjvCcmyD/WohP\n9WbbLXVQ8roTHrteg/ZGiEtxvnnPuN75th4zypttn4oqVGx1wiHwJuxbCZ2tTgtr4kVOQEy5AsbM\n7NthteoA7H4Ndr3qtLw62yA2GaZc7vR7TLsSEsf03/s6C4MmMERkMfAoEAk8paoP95ifBiwFpgAt\nwD+r6hZ33teBuwAFNgN3qGrLqbZngTE0qCrbDtWxfPMhXt58mNKqRiIELpiUzrVzxnL1OVmMSbIO\n6z5RhSPbnIDY8mc4GgCJhMkfhXNudr7tjxo9sDW1N0PpW0547FzuHOaJiodpH3M6zKdd5V1wATRU\nOi2erkNNDRXO9DEznXCYcoUTFtEeHeZsbXDe/+5XnUNY9Yec6ePOc1oe066CsXMhYmD74QZFYIhI\nJLALuBIoA1YDn1bVbSHL/BRoUNXvi0gB8LiqLhKRHOA9YKaqNovI88ByVf2/p9qmBcbgpapsKa9j\n+ZZDvLz5EHurm4iMEBZMTuea2dlcNTObzCQfro3oaHX+kFvroK0BWus//BMRBcljnU7N5HGQlD2o\nDimc4MgOt09iGVTtdE6BzbsEZt3s9CckpPtdoaOzw/nGvf2vsONvzs4zIhomXeq0PAqu6/s3745W\nOPC+czZT4E04vMmZHj/a+YY/ZZHzO3lc39/PmVJ16uk6dFW2BlDn0N20q2D6VTD58r4fHgzDYAmM\nBcBDqnq1+/zbAKr645Bl/g48rKrvus8DwEU4p/uuAs4F6oAXgcdU9bVTbdMCY3BRVTaV1bJ88yGW\nbznEgaPNREYIF01J57rZY7lyZhbpZ3MBXWeH07HYvVN3d/QfmlbnTm84cbnQcOhsO4t3JpCQ6exo\nksdB0lgnUJJz3MfutAH4YwegavfxkDiyzakv72I450aYcQMkZg5MHWcrGHQ637e/5ATIsT2AOMf6\nu671SJ1w+tdRdfoMugJi73vOIbCIKKeDuqsV4cO3+NNqrIKSN5xDV4F/QEutE6ATFziHrqZfDelT\nPTnrbLAExi3AYlW9y33+eeACVb0vZJn/BcSr6tdFZD5Q7C6zVkQeAH4ENAOvqepnT7KdJcASgAkT\nJpy/b98+T96PCY+qsv5ADS9vPsTyzYcpr2kmKkK4eFoG185yQiItISZ0BefQRN1B51tmXTnUHYL6\ng84hhBOCwN3JdzSHV0z0KIhNgphE53fPn96mxyQ6x5hjk5wzhGKToLM9pL6edbqPu86iCRWT5LZM\n3DDpftwVNOOc4DmbnVd14PjZTRWb6d7BnnMTzLwBkrLO/DUHg65Dadvd03UrtjjTx849fq1HZv7x\n5ZuPQenbxw8z1R5wpo+ecjwgJl3i/DsOFZ0dTsto96tOC6TrtN20SccPXeVdDFH90yIfSoGRjNPH\nMQ+nn6IA+BKwD/gTcCtQA/wReEFVf3eqbVoLwx/BoLL+wDH+vukwr2w5xMHaFqIjhcumpnHjtCg+\nmt1BYmvF8R1uz51vR8+uKfcbfGKW8y29e8fe9Tu5x84+ZCffNT0mESIH8LrU9mb3PXW9r4Pu4/Lj\n0xsOO+fvh4qIcs7ESR534mGv0JZL0jiIjnM6q7taEoc2OuuPv+B4SPhxaMVr1QHnkNX2vznXP4Bz\nxlHeJc4hnfK1zim8scnO4ayuzuq0PF/L7lc1+52Wx+7XYM87zt9LdIJz1tb0q5wA6cO//WAJjNMe\nkuqxvAB7gDnA1Thhc6c77wvAhar6lVNt0wJj4ASb69iycyfrt2xj757dxLdUkBNRw8ykBvJiaklp\nrySisRLnnIUQkbEhO8ae376HQB9BXwQ7naE1QgOzt8dtDR9eNy4VWmqcxzmFx0MidfzAvgc/1R08\nfq3H/lXOldVdAZFTOLBfEPzS1uRcZd4VIF0tqnHz4M43zuozOJPA8PITXg1ME5FJQDlwG/CZ0AVE\nJBVoUtU2nDOi3lHVOhHZD1woIqNwDkktAiwJBkpjlXMhVo9DL1pbTvPRMiLqDxEXbGQOTroDEA0a\nl4okdn0zPi/kW3JIIIwaPTyu/j0bEZFOGCZln3q5lroPH56rOwRpE2Hmjc7vkSh5HMz/kvMzUsW4\nQ7RMv9o9fLfdOXRVf3hAAtOzLahqh4jcB7yKc1rtUlXdKiJ3u/OfAGYAT4uIAluBO91574vIC8A6\noANYDzzpVa0jXme7842t65hp1c4TZqtEUhc1mv3tqZR1plElU0nInMDESVOZOT2f+PTxkDQW8eN8\n+uEoLtn5CT1Wb0xPIpA10/kZqE3ahXsjVEOlc0HVrlchUASt7lkZeQvpnHwFu9oyePNgNC+VKrub\nRhEbHc0VBWO4dvZYLsvPtNuUGjNMDJZDUmYwCQbh8Mbj532XrwPU6XCd+YnuAdP+trOe7/5lK0cb\n2xgVE8miGVl8bVY2l+WPIT7GhuQwZiSzwBjOWuud1kPXlaUNFYBAbiFc/m/OGRbuiKLBoPLz13fx\nX0UlzJuQyo9vns1Hp2cSF20hYYxxWGAMN1Ulbl/Eq85gasF2Z+yeKYucVsTUj31oALWG1g6+/ocN\nvL6tglsLx/ODG8+xAf6MMR9igTHUdbQ6Qyx0HWo6WupMzyyABV9xrhIdf8FJz6DYX93EXb9dTaCy\nkYeun8kXL8pDRupZTMaYU7LAGIrqDjnnYO9+zRnMrK3BudlN3iVw4VecC3nCOPWyOFDFV55Zhyo8\nfcd8Lp5m92k2xpycBcZQEOx0Oqm7DjV1DaKWnAtz/slpRUy6NOxholWV363ax0N/3cakjASe+kIh\neRk2hLgx5tQsMAar5hpnELJdrzmDkjVVOcNTj78APvaQ04o4i7H62zqCPPTXrfz+/f1cUTCGR2+b\nS1LcMLyq2hjT7ywwBpOq3c59Ana9BvtXgnY6QzFP/ZjTYT3lij7dw6C6oZV7freOD/Ye5Z7LpvDN\nq/KJjLD+CmNMeCwwBoO6Q/DG92DTH5znWbPh4q85h5pyC/vlXsjbDtbxpd+uoaqhlUdvm8sNc3P6\n/JrGmJHFAsNPHa2w6hfw9k+d018v+QYU3gkp/bszf3nzIf6f5zeSEh/NH+9ewJxcD+9qZowZtiww\n/LLrVXjlQec02Pzr4OofwujJ/bqJYFB57M3dPPLGbuaOT+XJz5/PmGS79akx5uxYYAy0qhJ49dvO\nKbHp0+Bzf3L6KPpZY2sH3/zjRl7ecphPnpfLj26aZVdtG2P6xAJjoLTWwzs/hZW/cK6ZuOpHMH8J\nRMWcft0zdOBoE1/67Rp2VdTz79fN4M6LJ9nFeMaYPrPA8FowCJufh9e/64zlNPdzsOi7nt1C84M9\nR7n7d2tp7wyy9PaPcFn+GE+2Y4wZeSwwvFS+Dl7+V+fWkjnnw22/d8568sizH+znP17cwoTRo/jV\nFwuZkpno2baMMSOPBYYXGirhzR/Auv9xBvq74Rdw7qchIsKTzbV3Bvnh37bx9Mp9fHR6Jo99eh4p\n8XYxnjGmf1lg9KfOdlj9FBT9GNobYcG98NF/cUaL9cixxja+8sw6VpZWs+TSyfzr4gK7GM8Y4wkL\njP4SKHJOk63c4VyRvfgnkDnd003uPFzPXb9dTUVtK//5qXP55Pm5nm7PGDOyWWD01bF98Nq/wfa/\nQloe3PYs5F9zxmM8nanXt1XwtefWMyo2iue+fCHnTUjzdHvGGGOBcbbammDFI7DiUZAIuOI/YMF9\nEO3thXGqyi/eCvCz13YyOyeFJz9fSHaKXYxnjPGeBcaZUoVtL8Kr/w51ZTDrFrjyB/0+nEdvmts6\n+dYLG/nbpkPcMHccP/nkHLsYzxgzYDwNDBFZDDwKRAJPqerDPeanAUuBKUAL8M+qukVE8oE/hCw6\nGfiuqj7iZb2nVbHVOU1277vOAIE3Pwl5Cwdk0wdrmlnyP2vYerCOf11cwN0fnWwX4xljBpRngSEi\nkcDjwJVAGbBaRF5S1W0hi30H2KCqN4lIgbv8IlXdCcwNeZ1yYJlXtZ5W01F468fOGVBxKXDdz+H8\n2/tlFNlwrN13lC//zzpa2jt56guFLJrhzUV/xhhzKl62MOYDJapaCiAizwE3AKGBMRN4GEBVd4hI\nnohkqWpFyDKLgICq7vOw1t4FO2Hd0/CP/xdaapyRZC//Tp/uSXGmnl9zgH9ftoVxqXE8+6ULmJaV\nNGDbNsaYUF4GRg5wIOR5GXBBj2U2AjcD74rIfGAikAuEBsZtwLMn24iILAGWAEyYMKHvVXfZtxJe\n/hYc3gwTL4ZrfgLZs/rv9U+jozPIj1/ewa/f28PFUzP4r8/MI3VU/487ZYwx4fK70/th4FER2QBs\nBtYDnV0zRSQG+ATw7ZO9gKo+CTwJUFhYqH2uqO6gM+7T5j9Ccg7cshTOudnz02RD1Ta1c9+z63h3\ndxV3LMzj366dQVSkN1eJG2NMuLwMjHJgfMjzXHdaN1WtA+4AEKcHdw9QGrLINcC6HoeovNHeAqse\nh3f+E4IdcOm34OKvQ0yC55sOVXKknrueXkN5TTM/+eRsbv1IP7aajDGmD7wMjNXANBGZhBMUtwGf\nCV1ARFKBJlVtA+4C3nFDpMunOcXhqH6hCrtegVe+Dcf2QMHH4aofwuhJnm62N0U7jnD/s+uJjY7g\n2S9dSGHewPWVGGPM6XgWGKraISL3Aa/inFa7VFW3isjd7vwngBnA0yKiwFbgzq71RSQB5wyrL3tV\nI+B0Zv/5y85w45/7M0xd5OnmTubA0Sbu+u0aCrKTePILheSkxvtShzHGnIynfRiquhxY3mPaEyGP\nVwK9Drikqo1Aupf1ARCfBl98CbLOgUj/Rnh9d3cVnUHl0dvmWVgYYwYlvzu9B4dxc/2ugOJAFVnJ\nsUzJHNg+E2OMCZedejMIBIPKykA1C6dk2NXbxphBywJjENh1pJ7qxjYWTPH+CJwxxpwtC4xBYEVJ\nNQAXTc3wuRJjjDk5C4xBYGWgirz0UdbZbYwZ1CwwfNbRGeT90qMsmGKtC2PM4GaB4bPN5bXUt3aw\ncKr1XxhjBjcLDJ8VB5z+iwWTLTCMMYObBYbPigNVFGQnkZ4Y63cpxhhzShYYPmpp72TN3mNcZP0X\nxpghwALDR+v2H6O1I8hFdv2FMWYIsMDw0cpANZERwgWTbVRaY8zgZ4HhoxUlVczOSSEpzr9BD40x\nJlwWGD5paO1gY1mtnU5rjBkyLDB8snrPUTqDah3expghwwLDJytKqoiJiuD8iWl+l2KMMWGxwPBJ\ncaCa8yekERcd6XcpxhgTFgsMHxxtbGPboTrrvzDGDCkWGD5YVeoOB2L9F8aYIcQCwwcrSqpIiIlk\nTm6K36UYY0zYLDB8sDJQzQWT04mOtI/fGDN0eLrHEpHFIrJTREpE5MFe5qeJyDIR2SQiH4jIrJB5\nqSLygojsEJHtIrLAy1oHyqHaZkqrGm04EGPMkONZYIhIJPA4cA0wE/i0iMzssdh3gA2qOgf4AvBo\nyLxHgVdUtQA4F9juVa0DqbjrdqzWf2GMGWK8bGHMB0pUtVRV24DngBt6LDMTeBNAVXcAeSKSJSIp\nwKXAr915bapa42GtA6Y4UM3ohBgKspP8LsUYY85IWIEhIje5O/Gu56kicuNpVssBDoQ8L3OnhdoI\n3Oy+5nxgIpALTAIqgd+IyHoReUpEEk5S2xIRWSMiayorK8N5O75RVYoDVSyYnE5EhPhdjjHGnJFw\nWxjfU9Xarifut/3v9cP2HwZSRWQD8FVgPdAJRAHnAb9U1XlAI/ChPhC3lidVtVBVCzMzM/uhJO/s\nrW7iUG0LC6z/whgzBEWFuVxvwXK6dcuB8SHPc91p3VS1DrgDQEQE2AOUAqOAMlV93130BU4SGEPJ\nipIqAOvwNsYMSeG2MNaIyM9FZIr783Ng7WnWWQ1ME5FJIhID3Aa8FLqAe2grxn16F/COqtap6mHg\ngIjku/MWAdvCrHXQWhmoZmxKHJMyej26Zowxg1q4LYyvAv8B/AFQ4HXg3lOtoKodInIf8CoQCSxV\n1a0icrc7/wlgBvC0iCiwFbizxzafcQOlFLclMlQFg07/xeUFY3AaU8YYM7SEFRiqetI+hNOstxxY\n3mPaEyGPVwLTT7LuBqDwTLc5WO04XM+xpnYW2um0xpghKtyzpF4XkdSQ52ki8qp3ZQ0/xQG3/8IG\nHDTGDFHh9mFkhF4HoarHgDHelDQ8FQeqmZyRwNiUeL9LMcaYsxJuYARFZELXExHJw+nLMGFo7wzy\nfmm1nU5rjBnSwu30/jfgPRF5GxDgEmCJZ1UNM5vKamls67ThQIwxQ1q4nd6viEghTkisB14Emr0s\nbDhZ6fZfWAvDGDOUhRUYInIX8ADOxXcbgAuBlcAV3pU2fKwoqWbG2GRGJ8ScfmFjjBmkwu3DeAD4\nCLBPVS8H5gHDYjBAr7W0d7J2/zEWWuvCGDPEhRsYLaraAiAise7IsvmnWccAa/cdo60jaKfTGmOG\nvHA7vcuT2A5OAAAUfklEQVTc6zBeBF4XkWPAPu/KGj6KA1VERgjzJ1lgGGOGtnA7vW9yHz4kIkVA\nCvCKZ1UNI8WBas7NTSExNtxsNsaYwemMb6Ckqm+r6kvuTZHMKdS3tLOprJaFU+10WmPM0OfpPb1H\nug/2HKUzqHY6rTFmWLDA8NCKkmpioyI4b0Ka36UYY0yfWWB4qDhQRWFeGnHRkX6XYowxfWaB4ZGq\nhlZ2HK634UCMMcOGBYZHVpVWA3Y7VmPM8GGB4ZHiQDVJsVHMzknxuxRjjOkXFhgeKS6p4oLJo4mK\ntI/YGDM82N7MA+U1zeytbmKB9V8YY4YRCwwPFJe4t2O1/gtjzDBigeGBlYFq0hNiyM9K8rsUY4zp\nN54GhogsFpGdIlIiIg/2Mj9NRJaJyCYR+UBEZoXM2ysim0Vkg4is8bLO/qSqrAhUceGUdCIixO9y\njDGm33g2Ip6IRAKPA1cCZcBqEXlJVbeFLPYdYIOq3iQiBe7yi0LmX66qVV7V6IXSqkYq6lpZaP0X\nxphhxssWxnygRFVL3YEKnwNu6LHMTOBNAPceG3kikuVhTZ6z/gtjzHDlZWDkAAdCnpe500JtBG4G\nEJH5wESc28ACKPCGiKwVkSUn24iILBGRNSKyprKyst+KP1vFgWpyUuOZmD7K71KMMaZf+d3p/TCQ\nKiIbgK8C64FOd97FqjoXuAa4V0Qu7e0FVPVJVS1U1cLMzMwBKfpkgkFlZWk1C6akI2L9F8aY4cXL\nu/qUA+NDnue607qpah1wB4A4e9g9QKk7r9z9fUREluEc4nrHw3r7bNuhOmqa2u1wlDFmWPKyhbEa\nmCYik0QkBrgNeCl0ARFJdecB3AW8o6p1IpIgIknuMgnAVcAWD2vtFysDXeNHWYe3MWb48ayFoaod\nInIf8CoQCSxV1a0icrc7/wlgBvC0iCiwFbjTXT0LWOYe1okCfq+qg/6WsCsCVUzOTCA7Jc7vUowx\npt95eqNpVV0OLO8x7YmQxyuB6b2sVwqc62Vt/a29M8gHe47yyfNyT7+wMcYMQX53eg8bGw/U0NTW\naf0XxphhywKjnxQHqhGBCydbYBhjhicLjH5SHKhi5thk0hJiTr+wMcYMQRYY/aC5rZN1+2pYONXO\njjLGDF8WGP1g7b5jtHUGWWD9F8aYYcwCox+sCFQRFSHMzxvtdynGGOMZC4x+UByoZu74VBJiPT1L\n2RhjfGWB0Ue1ze1sLqux02mNMcOeBUYffbDnKEGFi6zD2xgzzFlg9NGKkirioiOYNyHV71KMMcZT\nFhh9tDJQzUfyRhMbFel3KcYY4ykLjD6orG9lZ0W9nU5rjBkRLDD6YGWpDWdujBk5LDD6YGWgiqS4\nKGaNS/a7FGOM8ZwFRh+sKKnmgknpREXax2iMGf5sT3eWDhxtYv/RJhZOtf4LY8zIYIFxlux2rMaY\nkcYC4ywVB6rISIxhelai36UYY8yAsMA4C6pKcaCaBVMycO87bowxw54FxlkIVDZwpL7Vxo8yxowo\nFhhnodjtv1ho/RfGmBHE08AQkcUislNESkTkwV7mp4nIMhHZJCIfiMisHvMjRWS9iPzNyzrP1IqS\nKnJS4xk/Ot7vUowxZsB4FhgiEgk8DlwDzAQ+LSIzeyz2HWCDqs4BvgA82mP+A8B2r2o8G51BZVXp\nURZOTbf+C2PMiOJlC2M+UKKqparaBjwH3NBjmZnAmwCqugPIE5EsABHJBa4DnvKwxjO27WAdtc3t\ndjqtMWbE8TIwcoADIc/L3GmhNgI3A4jIfGAikOvOewT4FyB4qo2IyBIRWSMiayorK/uj7lMqDlQB\nWIe3MWbE8bvT+2EgVUQ2AF8F1gOdIvJx4Iiqrj3dC6jqk6paqKqFmZmZHpcLKwLVTB2TyJjkOM+3\nZYwxg4mXN6EuB8aHPM91p3VT1TrgDgBxOgT2AKXArcAnRORaIA5IFpHfqernPKz3tNo6gqzec5R/\nKsw9/cLGGDPMeNnCWA1ME5FJIhID3Aa8FLqAiKS68wDuAt5R1TpV/baq5qpqnrvem36HBcDGshqa\n2ztZYP0XxpgRyLMWhqp2iMh9wKtAJLBUVbeKyN3u/CeAGcDTIqLAVuBOr+rpDytKqhCBCyeP9rsU\nY4wZcF4ekkJVlwPLe0x7IuTxSmD6aV7jLeAtD8o7Y8WBamaNSyF1VMzpFzbGmGHG707vIaOprYP1\n+4/Z2VHGmBHLAiNMa/Yeo71TuWiq9V8YY0YmC4wwrQhUER0pfCQvze9SjDHGFxYYYVoZqGbe+DRG\nxXja7WOMMYOWBUYYapva2VJeywLrvzDGjGAWGGFYtaeaoNpwIMaYkc0CIwwrA9XERUcwb4L1Xxhj\nRi4LjDCsKKniI3mjiYmyj8sYM3LZHvA0jtS3sPtIAwvtdFpjzAhngXEaK93bsVr/hTFmpLPAOI3i\nkmqS46I4Z1yK36UYY4yv7KKC01gRqOLCyelERtjtWI0ZSO3t7ZSVldHS0uJ3KcNCXFwcubm5REdH\nn/VrWGCcwoGjTZQda+auiyf5XYoxI05ZWRlJSUnk5eXh3C7HnC1Vpbq6mrKyMiZNOvv9mR2SOoWu\n27Fah7cxA6+lpYX09HQLi34gIqSnp/e5tWaBcQorSqrJTIpl6phEv0sxZkSysOg//fFZWmCchKpS\nHKjmoin2DccYY8AC46R2H2mgqqHVTqc1ZoSqqanhF7/4xRmvd+2111JTU+NBRf6zwDiJ4hKn/+Ii\nu3+3MSPSyQKjo6PjlOstX76c1NRUr8rylZ0ldRIrAtWMHx3P+NGj/C7FmBHv+3/dyraDdf36mjPH\nJfO968856fwHH3yQQCDA3LlziY6OJi4ujrS0NHbs2MGuXbu48cYbOXDgAC0tLTzwwAMsWbIEgLy8\nPNasWUNDQwPXXHMNF198McXFxeTk5PCXv/yF+Pj4fn0fA8laGL3oDCqrSqtZaK0LY0ashx9+mClT\nprBhwwZ++tOfsm7dOh599FF27doFwNKlS1m7di1r1qzhscceo7q6+kOvsXv3bu699162bt1Kamoq\nf/rTnwb6bfQra2H0Ykt5LfUtHXb/C2MGiVO1BAbK/PnzT7iG4bHHHmPZsmUAHDhwgN27d5OefuI+\nY9KkScydOxeA888/n7179w5YvV7wtIUhIotFZKeIlIjIg73MTxORZSKySUQ+EJFZ7vQ49/lGEdkq\nIt/3ss6eit3xoywwjDFdEhISuh+/9dZbvPHGG6xcuZKNGzcyb968Xq9xiI2N7X4cGRl52v6Pwc6z\nwBCRSOBx4BpgJvBpEZnZY7HvABtUdQ7wBeBRd3orcIWqngvMBRaLyIVe1dpTcaCK6VmJjEmKG6hN\nGmMGmaSkJOrr63udV1tbS1paGqNGjWLHjh2sWrVqgKvzh5eHpOYDJapaCiAizwE3ANtClpkJPAyg\nqjtEJE9EslS1Amhwl4l2f9TDWru1dnSyeu9RbvvIhIHYnDFmkEpPT2fhwoXMmjWL+Ph4srKyuuct\nXryYJ554ghkzZpCfn8+FFw7Y91lfeRkYOcCBkOdlwAU9ltkI3Ay8KyLzgYlALlDhtlDWAlOBx1X1\n/d42IiJLgCUAEyb0fSe/YX8NLe1Bu/7CGMPvf//7XqfHxsby8ssv9zqvq58iIyODLVu2dE//5je/\n2e/1DTS/z5J6GEgVkQ3AV4H1QCeAqnaq6lycAJnf1b/Rk6o+qaqFqlqYmZnZ54JWBKqJELhgsgWG\nMcaE8rKFUQ6MD3me607rpqp1wB0A4oy/sQco7bFMjYgUAYuBLXhsZaCK2TkppMSf/RDAxhgzHHnZ\nwlgNTBORSSISA9wGvBS6gIikuvMA7gLeUdU6EckUkVR3mXjgSmCHh7UC0Njawfr9NSyw6y+MMeZD\nPGthqGqHiNwHvApEAktVdauI3O3OfwKYATwtIgpsBe50Vx/rTo/ECbXnVfVvXtXaZfXeo3QE1fov\njDGmF55euKeqy4HlPaY9EfJ4JTC9l/U2AfO8rK03KwPVREcKH8kbPdCbNsaYQc/vTu9BZUWginkT\n0oiPifS7FGOMGXQsMFw1TW1sPVhn40cZY85KYqJzo7WDBw9yyy239LrMZZddxpo1a075Oo888ghN\nTU3dzwfTcOkWGK5VpdWowkVTrf/CGHP2xo0bxwsvvHDW6/cMjME0XLoNPugqDlQzKiaSc3MHxz+M\nMSbEyw/C4c39+5rZs+Gah086+8EHH2T8+PHce++9ADz00ENERUVRVFTEsWPHaG9v54c//CE33HDD\nCevt3buXj3/842zZsoXm5mbuuOMONm7cSEFBAc3Nzd3L3XPPPaxevZrm5mZuueUWvv/97/PYY49x\n8OBBLr/8cjIyMigqKuoeLj0jI4Of//znLF26FIC77rqLr33ta+zdu3fAhlG3FoZrRUkVH8kbTUyU\nfSTGGLj11lt5/vnnu58///zzfPGLX2TZsmWsW7eOoqIivvGNb6B68lGLfvnLXzJq1Ci2b9/O97//\nfdauXds970c/+hFr1qxh06ZNvP3222zatIn777+fcePGUVRURFFR0QmvtXbtWn7zm9/w/vvvs2rV\nKn71q1+xfv16YOCGUbcWBlBR10KgspF/Khx/+oWNMQPvFC0Br8ybN48jR45w8OBBKisrSUtLIzs7\nm69//eu88847REREUF5eTkVFBdnZ2b2+xjvvvMP9998PwJw5c5gzZ073vOeff54nn3ySjo4ODh06\nxLZt206Y39N7773HTTfd1D1q7s0338y7777LJz7xiQEbRt0CA2d0WoCFU63D2xhz3Kc+9SleeOEF\nDh8+zK233sozzzxDZWUla9euJTo6mry8vF6HNT+dPXv28LOf/YzVq1eTlpbG7bffflav06XnMOqh\nh776kx1/AYpLqkmJj2bG2GS/SzHGDCK33norzz33HC+88AKf+tSnqK2tZcyYMURHR1NUVMS+fftO\nuf6ll17aPYDhli1b2LRpEwB1dXUkJCSQkpJCRUXFCQMZnmxY9UsuuYQXX3yRpqYmGhsbWbZsGZdc\nckk/vtvTG/EtDFWlOFDNgsnpREaI3+UYYwaRc845h/r6enJychg7diyf/exnuf7665k9ezaFhYUU\nFBSccv177rmHO+64gxkzZjBjxgzOP/98AM4991zmzZtHQUEB48ePZ+HChd3rLFmyhMWLF3f3ZXQ5\n77zzuP3225k/fz7gdHrPmzdvQO/iJ6fqsBlqCgsL9XTnOPfU0t7Jd/+yhYVTM7hhbo5HlRljztT2\n7duZMWOG32UMK719piKyVlULw1l/xLcw4qIj+d+3nOt3GcYYM+hZH4YxxpiwWGAYYwat4XTI3G/9\n8VlaYBhjBqW4uDiqq6stNPqBqlJdXU1cXFyfXmfE92EYYwan3NxcysrKqKys9LuUYSEuLo7c3Nw+\nvYYFhjFmUIqOjmbSpEl+l2FC2CEpY4wxYbHAMMYYExYLDGOMMWEZVld6i0glcOrBXU4uA6jqx3KG\nMvssTmSfx4ns8zhuOHwWE1U1M5wFh1Vg9IWIrAn38vjhzj6LE9nncSL7PI4baZ+FHZIyxhgTFgsM\nY4wxYbHAOO5JvwsYROyzOJF9Hieyz+O4EfVZWB+GMcaYsFgLwxhjTFgsMIwxxoRlxAeGiCwWkZ0i\nUiIiD/pdj59EZLyIFInINhHZKiIP+F2T30QkUkTWi8jf/K7FbyKSKiIviMgOEdkuIgv8rslPIvJ1\n9+9ki4g8KyJ9Gwp2CBjRgSEikcDjwDXATODTIjLT36p81QF8Q1VnAhcC947wzwPgAWC730UMEo8C\nr6hqAXAuI/hzEZEc4H6gUFVnAZHAbf5W5b0RHRjAfKBEVUtVtQ14DrjB55p8o6qHVHWd+7geZ4cw\nYm90LiK5wHXAU37X4jcRSQEuBX4NoKptqlrjb1W+iwLiRSQKGAUc9Lkez430wMgBDoQ8L2ME7yBD\niUgeMA94399KfPUI8C9A0O9CBoFJQCXwG/cQ3VMikuB3UX5R1XLgZ8B+4BBQq6qv+VuV90Z6YJhe\niEgi8Cfga6pa53c9fhCRjwNHVHWt37UMElHAecAvVXUe0AiM2D4/EUnDORoxCRgHJIjI5/ytynsj\nPTDKgfEhz3PdaSOWiETjhMUzqvpnv+vx0ULgEyKyF+dQ5RUi8jt/S/JVGVCmql0tzhdwAmSk+hiw\nR1UrVbUd+DNwkc81eW6kB8ZqYJqITBKRGJxOq5d8rsk3IiI4x6i3q+rP/a7HT6r6bVXNVdU8nP8X\nb6rqsP8GeTKqehg4ICL57qRFwDYfS/LbfuBCERnl/t0sYgScBDCib9Gqqh0ich/wKs5ZDktVdavP\nZflpIfB5YLOIbHCnfUdVl/tYkxk8vgo84365KgXu8Lke36jq+yLyArAO5+zC9YyAYUJsaBBjjDFh\nGemHpIwxxoTJAsMYY0xYLDCMMcaExQLDGGNMWCwwjDHGhMUCw5hBQEQusxFxzWBngWGMMSYsFhjG\nnAER+ZyIfCAiG0Tkv937ZTSIyP/n3hvhHyKS6S47V0RWicgmEVnmjj+EiEwVkTdEZKOIrBORKe7L\nJ4bcb+IZ9wpiYwYNCwxjwiQiM4BbgYWqOhfoBD4LJABrVPUc4G3ge+4qvwX+VVXnAJtDpj8DPK6q\n5+KMP3TInT4P+BrOvVkm41x5b8ygMaKHBjHmDC0CzgdWu1/+44EjOMOf/8Fd5nfAn937R6Sq6tvu\n9KeBP4pIEpCjqssAVLUFwH29D1S1zH2+AcgD3vP+bRkTHgsMY8InwNOq+u0TJor8R4/lzna8ndaQ\nx53Y36cZZOyQlDHh+wdwi4iMARCR0SIyEefv6BZ3mc8A76lqLXBMRC5xp38eeNu9k2GZiNzovkas\niIwa0HdhzFmybzDGhElVt4nIvwOviUgE0A7ci3MzofnuvCM4/RwAXwSecAMhdHTXzwP/LSI/cF/j\nUwP4Now5azZarTF9JCINqprodx3GeM0OSRljjAmLtTCMMcaExVoYxhhjwmKBYYwxJiwWGMYYY8Ji\ngWGMMSYsFhjGGGPC8v8DCLwRIj1I0OQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12dcd8a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoints\n",
    "\n",
    "args \n",
    "- filepath - str  can use formating to put epoch number etc {epoc}\n",
    "- monitor - qunatity to monitor  \n",
    "- verbose - 0 or 1  \n",
    "- save_best_only - only save if better than before  \n",
    "- mode - use 'auto'  \n",
    "- save_weights_only - if false then will save whole model\n",
    "- period - the interval between epochs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./checkpoints/weights_{epoch:02d}_{val_acc:.2f}.hdf5', verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss did not improve\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 00002: val_loss improved from 0.09254 to 0.09184, saving model to ./checkpoints/weights_02_0.98.hdf5\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 00009: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12de1b0b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard Callback\n",
    "\n",
    "args\n",
    "- log_dir : string , must exist\n",
    "- histogram_freq : freq in epochs\n",
    "- write_graph : true or false for seeing the graph in TB  \n",
    "- write_grads :writing the gradients  not working 2.04\n",
    "- batch_size : size of batches for histogram  \n",
    "- write_images :whether to write model weights to see  \n",
    "- embeddings_freq : \n",
    "- embeddings_layer_names :\n",
    "- embeddings_metadata :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TB = TensorBoard(log_dir='./logs', histogram_freq=1,\n",
    "                            write_graph=True,  write_images=False)\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Dense1/kernel:0 is illegal; using Dense1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Dense1/bias:0 is illegal; using Dense1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name Dense2/kernel:0 is illegal; using Dense2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name Dense2/bias:0 is illegal; using Dense2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12de42668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[TB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'54' at http://Sams-MacBook-Pro.local:6006\n",
      "(Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping - stop training when a monitored quanity has stopped improving\n",
    "args\n",
    "- monitor : what to monitor 'val_loss', 'acc'\n",
    "- min_delta :minimum change to qualify as improvement\n",
    "- patience : number of epocs with no improvement before you stop\n",
    "- verbose : verbosity mode\n",
    "- mode : 'auto' , can be 'min' or 'max' determines direction of improvement. Auto = based on monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=0,verbose=0,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0137 - acc: 0.9968 - val_loss: 0.1277 - val_acc: 0.9835\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0160 - acc: 0.9963 - val_loss: 0.1229 - val_acc: 0.9846\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0155 - acc: 0.9969 - val_loss: 0.1248 - val_acc: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e33e978>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above stopped after 3 epochs instead of 10 as validation loss didn't get better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler\n",
    "arg\n",
    "- schedule - this will be function that takes epoch number(int) and returns new Learning Rate (float) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# learning rate schedule for dropping every 10 epochs\n",
    "def LRDropping(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.9\n",
    "    epochs_drop = 3.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009000000000000001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRDropping(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LRDrop = LearningRateScheduler(LRDropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.1223 - val_acc: 0.9848\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0134 - acc: 0.9972 - val_loss: 0.1182 - val_acc: 0.9845\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0099 - acc: 0.9977 - val_loss: 0.1194 - val_acc: 0.9847\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0131 - acc: 0.9974 - val_loss: 0.1291 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0095 - acc: 0.9978 - val_loss: 0.1212 - val_acc: 0.9854\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0085 - acc: 0.9980 - val_loss: 0.1331 - val_acc: 0.9835\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0091 - acc: 0.9981 - val_loss: 0.1469 - val_acc: 0.9845\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0066 - acc: 0.9983 - val_loss: 0.1431 - val_acc: 0.9843\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0074 - acc: 0.9984 - val_loss: 0.1323 - val_acc: 0.9850\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0064 - acc: 0.9984 - val_loss: 0.1249 - val_acc: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b2b1828>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[LRDrop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000729\n"
     ]
    }
   ],
   "source": [
    "#print out the learning rate\n",
    "print(K.eval(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau\n",
    "args\n",
    "- monitor : quality to be monitored eg. 'val_loss' , 'val_acc'\n",
    "- factor : the factor by which the current LR be multiplied  \n",
    "- patience : number of epochs with no improvement  \n",
    "- verbose : 1 = update messages 0 nothing\n",
    "- mode : 'auto'  eg. is improvment up or down 'min' 'max'\n",
    "- epsilon : threshold for measuring the new optimum, to only focus on significant changes  \n",
    "- cooldown :number of epochs to wait before any new changes\n",
    "- min_lr: the lowest lr allowed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce_LR = ReduceLROnPlateau(monitor='val_loss',factor = 0.9, patience=3,cooldown=2, min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0066 - acc: 0.9987 - val_loss: 0.1240 - val_acc: 0.9858\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0062 - acc: 0.9987 - val_loss: 0.1491 - val_acc: 0.9839\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0077 - acc: 0.9986 - val_loss: 0.1414 - val_acc: 0.9861\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0078 - acc: 0.9986 - val_loss: 0.1402 - val_acc: 0.9853\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0062 - acc: 0.9986 - val_loss: 0.1438 - val_acc: 0.9856\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0064 - acc: 0.9987 - val_loss: 0.1358 - val_acc: 0.9855\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0055 - acc: 0.9989 - val_loss: 0.1328 - val_acc: 0.9857\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0041 - acc: 0.9992 - val_loss: 0.1402 - val_acc: 0.9856\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0054 - acc: 0.9989 - val_loss: 0.1430 - val_acc: 0.9862\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0037 - acc: 0.9992 - val_loss: 0.1561 - val_acc: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121d01f98>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[reduce_LR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00059049\n"
     ]
    }
   ],
   "source": [
    "#print out the learning rate\n",
    "print(K.eval(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LambdaCallback a way to call anon functions in the callback\n",
    "args\n",
    "- on_epoch_being - called at begin of epoch -takes epoch,logs\n",
    "- on_epoch_end - called at end of epoch -takes epoch,logs\n",
    "- on_batch_begin _ called a begin of a batch -takes batch,logs\n",
    "- on_batch_end :-takes epoch,logs\n",
    "- on_train_begin - -takes logs\n",
    "- on_train_end - -takes logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_print = LambdaCallback(on_epoch_begin=lambda epoch,logs: print(\"lr:\",K.eval(model.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "lr: 0.00059049\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0113 - acc: 0.9981 - val_loss: 0.1359 - val_acc: 0.9845\n",
      "lr: 0.001\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0110 - acc: 0.9981 - val_loss: 0.1544 - val_acc: 0.9825\n",
      "lr: 0.001\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0098 - acc: 0.9982 - val_loss: 0.1543 - val_acc: 0.9842\n",
      "lr: 0.0009\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0098 - acc: 0.9980 - val_loss: 0.1482 - val_acc: 0.9848\n",
      "lr: 0.0009\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0088 - acc: 0.9983 - val_loss: 0.1342 - val_acc: 0.9864\n",
      "lr: 0.0009\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0079 - acc: 0.9983 - val_loss: 0.1308 - val_acc: 0.9858\n",
      "lr: 0.00081\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0077 - acc: 0.9986 - val_loss: 0.1452 - val_acc: 0.9848\n",
      "lr: 0.00081\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0090 - acc: 0.9983 - val_loss: 0.1327 - val_acc: 0.9861\n",
      "lr: 0.00081\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0051 - acc: 0.9987 - val_loss: 0.1451 - val_acc: 0.9855\n",
      "lr: 0.000729\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0065 - acc: 0.9989 - val_loss: 0.1394 - val_acc: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e978550>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[lr_print,LRDrop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
